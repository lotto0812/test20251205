# PDF QA PoC（複数PDF対応）

複数のPDFファイルを読み込み、Streamlit上で日本語の質問ができるPoCツールです。

## 📋 プロジェクト概要

このアプリケーションは、以下のことができます：

- **複数PDFのアップロード**: 2つ以上のPDFファイルを同時にアップロード
- **テキスト抽出・チャンク化**: PDFから自動でテキストを抽出し、検索しやすい単位に分割
- **類似検索**: 日本語の質問に対して、関連する情報を複数のPDFから横断的に検索
- **出典表示**: どのPDFの何ページから情報が見つかったかを表示

## 🛠️ 技術スタック

| 用途 | ライブラリ |
|------|-----------|
| UI | Streamlit |
| PDF処理 | pdfplumber |
| 埋め込みモデル | sentence-transformers (paraphrase-multilingual-MiniLM-L12-v2) |
| 数値計算 | NumPy |

## 📁 ファイル構成

```
pdf_qa_streamlit/
├── app.py              # Streamlitメインアプリケーション
├── pdf_utils.py        # PDF処理ユーティリティ（テキスト抽出・チャンク化）
├── embedding_utils.py  # 埋め込み生成・類似度計算
├── requirements.txt    # 依存パッケージ一覧
└── README.md           # このファイル
```

## 🚀 セットアップ手順

### 1. 必要な環境

- Python 3.9 以上（3.10, 3.11 推奨）
- pip（Pythonパッケージマネージャー）

### 2. 仮想環境の作成（推奨）

```bash
# 仮想環境を作成
python -m venv venv

# 仮想環境を有効化（Windows）
venv\Scripts\activate

# 仮想環境を有効化（macOS/Linux）
source venv/bin/activate
```

### 3. 依存パッケージのインストール

```bash
pip install -r requirements.txt
```

> ⚠️ **注意**: 初回インストール時は、PyTorchとsentence-transformersのダウンロードに数分かかることがあります。

### 4. アプリケーションの起動

```bash
streamlit run app.py
```

ブラウザが自動的に開き、`http://localhost:8501` でアプリケーションが表示されます。

## 📖 使い方

### 基本的な操作手順

1. **PDFをアップロード**
   - 左サイドバーの「PDFファイルを選択」でPDFをアップロード
   - 複数ファイルを選択可能（ドラッグ＆ドロップも対応）

2. **インデックスを作成**
   - 「インデックス作成」ボタンをクリック
   - PDFのテキスト抽出と埋め込みベクトル生成が行われます
   - 初回は埋め込みモデルのダウンロードに数分かかります

3. **質問を入力**
   - メイン画面の入力欄に日本語で質問を入力
   - 「検索」ボタンをクリック

4. **結果を確認**
   - 関連する情報が類似度順に表示されます
   - 各結果には、ファイル名・ページ番号・類似度スコアが含まれます

### 質問の例

- 「この文書の主なポイントは何ですか？」
- 「○○について説明している部分はどこですか？」
- 「△△の定義は何ですか？」
- 「□□と××の違いは何ですか？」

## 🔧 設定・カスタマイズ

### チャンクサイズの調整

`pdf_utils.py` の `chunk_text` 関数でチャンクサイズを調整できます：

```python
def chunk_text(text: str, max_chars: int = 800, overlap: int = 100) -> List[str]:
    # max_chars: 1チャンクの最大文字数
    # overlap: チャンク間の重複文字数
```

### 埋め込みモデルの変更

`embedding_utils.py` の `MODEL_NAME` を変更することで、別のモデルを使用できます：

```python
# 日本語に強いモデル例
MODEL_NAME = "paraphrase-multilingual-MiniLM-L12-v2"  # 現在の設定
# MODEL_NAME = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"  # より高精度
```

### 類似度の閾値

検索画面のスライダーで類似度の閾値を調整できます。デフォルトは0.3です。

## 📊 仕組みの説明

### 処理の流れ

```
[PDFアップロード]
       ↓
[テキスト抽出] ← pdfplumberでページごとにテキストを抽出
       ↓
[チャンク化] ← 長いテキストを800文字程度の塊に分割
       ↓
[埋め込み生成] ← sentence-transformersでテキストをベクトルに変換
       ↓
[インデックス保存] ← session_stateに保存
       ↓
[質問入力]
       ↓
[質問の埋め込み] ← 質問文もベクトルに変換
       ↓
[類似度計算] ← コサイン類似度で全チャンクと比較
       ↓
[結果表示] ← 類似度の高い上位N件を表示
```

### 埋め込み（Embedding）とは

- テキストを数百次元の数値ベクトル（配列）に変換する技術
- 似た意味のテキストは、似たベクトルになります
- ベクトル同士の「コサイン類似度」を計算することで、意味的な近さを数値化できます

### コサイン類似度とは

- 2つのベクトルの「角度の近さ」を測る指標
- -1.0 〜 1.0 の値を取り、1.0に近いほど類似している
- このアプリでは、0.3以上の類似度を「関連あり」として表示します

## ⚠️ 制限事項

- **大きなPDFの処理時間**: ページ数が多いPDFは処理に時間がかかります
- **スキャンPDF非対応**: 画像として保存されたPDF（OCRが必要なもの）はテキスト抽出できません
- **メモリ使用量**: 多くのPDFをアップロードすると、メモリ使用量が増加します
- **インデックスの永続化なし**: アプリを再起動するとインデックスがクリアされます
- **LLM回答生成なし**: 自然な文章での回答生成は未実装（抽出型のみ）

## 🔮 将来の拡張案

- [ ] **インデックスの永続化**: FAISSやChromaDBを使った高速検索
- [ ] **LLMによる回答生成**: OpenAI GPTやClaude APIを使った自然な回答
- [ ] **OCR対応**: スキャンPDFからのテキスト抽出
- [ ] **PDFのタグ付け・フィルタリング**: 特定のPDFのみを検索対象に
- [ ] **チャット風インターフェース**: 会話形式での質問応答
- [ ] **ハイライト表示**: PDF内の該当箇所をハイライト
- [ ] **ユーザー認証**: 複数ユーザー対応

## 🐛 トラブルシューティング

### 「ModuleNotFoundError」が発生する

依存パッケージがインストールされていません。以下を実行してください：

```bash
pip install -r requirements.txt
```

### 埋め込みモデルのダウンロードが進まない

ネットワーク接続を確認してください。初回は約500MB程度のダウンロードが必要です。

### PDFからテキストが抽出できない

- スキャンPDF（画像PDF）は対応していません
- パスワード保護されたPDFは開けません
- 破損したPDFファイルは処理できません

### メモリ不足エラーが発生する

アップロードするPDFの数を減らすか、より少ないページ数のPDFを使用してください。

## 📝 ライセンス

このプロジェクトはMITライセンスの下で公開されています。

## 🙏 謝辞

- [Streamlit](https://streamlit.io/) - 素晴らしいWebアプリフレームワーク
- [sentence-transformers](https://www.sbert.net/) - 高品質な埋め込みモデル
- [pdfplumber](https://github.com/jsvine/pdfplumber) - 信頼性の高いPDF処理ライブラリ

